## Credit Card Fraud Detection<br>
ğŸš€ Project: Credit Card Fraud Detection using Machine Learning
<br>
<B>Overview</B><br>
This project focuses on detecting fraudulent credit card transactions using machine learning models. Given the severe consequences of fraud, a robust predictive model is essential for financial security. The dataset is highly imbalanced, requiring advanced techniques to ensure accurate fraud detection.
<br>
We apply Random Forest and XGBoost, two powerful models, along with oversampling techniques (ROSE) to handle class imbalance.<br> The effectiveness of our models is evaluated using confusion matrices, ROC curves, and AUC scores.
<br>
 ### Objectives<br>
âœ” Preprocess the dataset, handling missing values and imbalanced classes.<br>
âœ” Balance the dataset using ROSE (Random Over-Sampling Examples).<br>
âœ” Train and evaluate machine learning models (Random Forest & XGBoost).<br>
âœ” Analyze performance using confusion matrices, AUC scores, and ROC curves.<br>
<br>
ğŸ“Š Data Preprocessing & Class Imbalance Handling
<br>
âœ” Checked missing values and removed inconsistencies.<br>
âœ” Visualized the distribution of fraud vs non-fraud transactions.<br>
âœ” Used ROSE to balance the dataset, ensuring that minority (fraudulent) cases are properly represented in training.
<br>
ğŸ“Œ<B> Key Finding: </B>
<br>
Before balancing, the dataset was heavily skewed toward non-fraudulent transactions. Using ROSE significantly improved model learning by creating a more balanced dataset.
<br>
Machine Learning Models Used<br>
1ï¸âƒ£ Random Forest Classifier<br>
Ensemble-based model that improves accuracy and reduces overfitting.<br>
Feature importance ranking helps identify key fraud indicators.<br>
Evaluated using confusion matrix and accuracy score.
<br>
ğŸ“Œ<B> Key Findings:</B><br> 
The Random Forest model performed well, effectively identifying fraudulent cases with high precision and recall.
<br>
2ï¸âƒ£ XGBoost (Extreme Gradient Boosting)<br>
A highly efficient boosting algorithm optimized for structured data.<br>
Trained on the balanced dataset with 100 boosting rounds.<br>
Evaluated using ROC curve and AUC score.<br>
ğŸ“Œ<B> Key Findings:</B> 
<br>XGBoost outperformed Random Forest, achieving a higher AUC score, indicating a better separation between fraudulent and non-fraudulent transactions.
<br>
ğŸ“ˆ Performance Evaluation<br>
âœ” Confusion Matrices â€“ Showed significant improvement in fraud detection after balancing the dataset.<br>
âœ” AUC-ROC Curve â€“ Used to measure the true positive rate vs false positive rate.<br>
âœ” Feature Importance â€“ Identified key transaction features contributing to fraud detection.
<br>
ğŸ“Œ<B> Key Findings:</B><br> The XGBoost model achieved the highest AUC score, indicating superior fraud detection capability.
